---
title: "My Computational Musiciology Portfolio! "
author: "Judith"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(flexdashboard)
library(corrplot)
```

#  Keygram visualisation
```{r, echo=FALSE}
library(tidyverse)
source("compmus.R")
"features/ahram-j-1.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    key_templates,         # Change to chord_templates if desired
    norm = "euclidean",       # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "angular"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_classic() 

```
<br><br><br>
In the keygram graph, we can notice the most intense color values, especially between 0-100 seconds, around C major and G major. Additionally, E minor appears relatively stable, with less variation in color intensity, with fewer yellow and greenish hues. This is interesting because, according to the Circle of Fifths, E minor is the relative minor of G major. B and E major, and G and C minor are also noticeable.

# Chordogram visualisation 
```{r, echo=FALSE}
library(tidyverse)
source("compmus.R")
"features/ahram-j-1.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    chord_templates,         # Change to chord_templates if desired
    norm = "manhattan",       # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "manhattan"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_classic() 

```
<br><br><br>
In the choreography visualization we can see very intense values throughout the whole track for E minor, also noticeable is C major. In the first few second of the track we van see darker hues of B minor, G major and a bit of B major. Additionally at the ned of the track we see now light hues, and darker blocks from E major to A:7 and E minor to A minor.  

# Chroma visualisation
```{r, echo=FALSE}
library(tidyverse)
source("compmus.R")

"features/ahram-j-1.json" |>                           # Change the track
  compmus_chroma(norm = "identity") |>                 # Change the norm
  ggplot(aes(x = time, y = pc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:11,
    minor_breaks = NULL,
    labels = c(
                "C", "C#|Db", "D", "D#|Eb",
                "E", "F", "F#|Gb", "G",
                "G#|Ab", "A", "A#|Bb", "B"
              )
  ) +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic()   
```

# Intorduction

On this page I am going to compare my two songs to my class corpus. 
I am unfortunately not a musician, so I decided to generate a song and choose a royalty free song.

Song 1:
I generated this song by using Soundful’s free AI music generator. First I had to choose genre, I chose pop rock. Then I had to decide for the speed/BPM. I decided 121 BPM. For chords and scales, I selected F# minor. I wanted to select two different songs, so for this song I chose a somewhat faster and energetic song.

Song 2:
I picked this song from the site from Pixabay. Because I had the idea to selected two different songs, I wanted a ‘slower’ song with more calm vibes, opposed to the faster rock song. However towards the end of the song there is a fragment that sound heroic and cinematic, which I find to be an interesting component in this song. Also, I wanted to have a human created song, so I can maybe analyse if there are differences between the AI generated song (I filtered the songs on this site to be strictly human generated). Song: Sweet Dreams by: Lexin_Music.



# first visualisation
```{r, echo=FALSE}
library(readr)
compmus2025 <- read_csv("compmus2025.csv")
correlation_compmus2025 <- cor(compmus2025[sapply(compmus2025, is.numeric)], use = "pairwise.complete.obs")
corrplot(correlation_compmus2025, method = 'number')
title("Correlations between the parameters of the classes' songs", line=3.5)
```
<br><br><br>
<div style="margin-top: 15px;"> This is a informative plot, that calculates the correlation between each parameter pair. This is useful for further research and plots. </div> 

# Second visualisation 
```{r, echo=FALSE}
library(ggplot2)

compmus2025 |>                  
  ggplot(                     
    aes(
      x = tempo,
      y = arousal,
      size = instrumentalness,
      colour = danceability
    )
  ) +
  geom_point() +              # Scatter plot (RE-ADDED)
  geom_rug(linewidth = 0.1) + # Fringes to show data distribution (RE-ADDED)
  scale_x_continuous(         
    limits = c(50, 200),
    breaks = c(50, 100, 150, 200),
    minor_breaks = NULL       
  ) +
  scale_y_continuous(         
    limits = c(1, 9),
    breaks = c(1, 5, 9),
    minor_breaks = NULL
  ) +
  scale_colour_viridis_c() +  
  scale_size_continuous(      
    trans = "exp",            
    guide = "none"            
  ) +
  theme_light() +             
  labs(                       
    x = "Engagingness",
    y = "Arousal",
    colour = "Valence"
  ) + ggtitle('relation between three parameters compmus2025')
```
<br><br><br>
<div style="margin-top: 15px;"> As a result of the correlation matrix, I thought it was a good idea to improve the visualisation from class, by first implementing it on the class data instead, and use three parameters that are highly (positive) correlated. I unfortunatly do not have the parameters of my own songs yet, otherwise I would have put my songs in this plot, to show the relationship between my songs and the songs of the class. </div> 
